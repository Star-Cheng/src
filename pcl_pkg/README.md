# README

## xvsdk

### SonyTofLibMode

+ sf: 单频: 只使用一个固定的调制频率来发射光信号。这种模组的特点是结构简单、成本较低，但在某些情况下可能会受到环境光干扰或测量范围的限制。
+ df: 双频: 使用两个不同的调制频率来发射光信号。这种模组的特点是可以通过双频调制技术提高测量精度和抗干扰能力。双频 TOF 模组通常会在不同的频率下进行多次测量，然后通过算法融合这些测量结果，从而获得更准确的距离信息
+ IQMIX：设备端只进行 IQ（In-phase 和 Quadrature）计算，其余的深度计算和处理工作由主机端的SDK 完成
+ LABELIZE: 几乎完整的 "raw to depth" 处理在设备端完成，主机端的SDK 只进行 labelize（标记）处理
+ M2MIX: 设备端完成 IQ 计算和深度计算（包括一些过滤器，如空间过滤器、时间过滤器、epsilion IQ 过滤器），其余过程由主机端的SDK 处理

### TOF&TOR IR

+ TOF：泛指基于光脉冲飞行时间原理的测距技术，其光源可以是红外光或激光​（如VCSEL或EEL）。通过发射光脉冲并测量其往返时间计算距离，适用于多种场景，例如3D建模、手势识别等
+ TOF IR：特指使用红外光（Infrared）作为光源的TOF技术。例如，iToF（间接飞行时间）常采用调制的红外光信号，通过相位差间接计算距离。这类技术对光源波长有明确限制（如940nm红外光），以减少环境光干扰

## FAST_LIO

### 传感器搭档：激光雷达 + 陀螺仪

+ 激光雷达​（LiDAR）相当于“眼睛”，负责扫描周围环境，生成3D点云（类似无数个点组成的立体图）。
+ ​陀螺仪​（IMU）相当于“平衡感”，能感知机器人的加速度和旋转速度。
+ 单独用LiDAR容易在快速移动时“看花眼”（点云变形），而单独用IMU会“漂移”（误差累积）。Fast LIO把两者数据拧成一股绳，互相弥补缺点。

### ​核心武器：迭代扩展卡尔曼滤波（IEKF）​

+ 想象你在拼拼图，每拼一块就调整整体图案。Fast LIO用IEKF不断“猜-测-修正”：
+ ​猜：用IMU预测机器人下一步的位置（比如：“我向左转了10度，应该在这个位置”）。
+ 测：用LiDAR扫描实际环境，对比预测的位置和真实点云的差距。
+ ​修正：快速调整误差，得到更准的位置。

### ​为啥“Fast”（快）？

+ ​省计算：传统方法要匹配整个点云，Fast LIO只挑关键特征点（比如墙角、边缘），计算量暴降。
+ ​反向补偿：机器人一边动一边扫描，点云会变形。Fast LIO用IMU数据反向修正，就像给模糊照片“去马赛克”。

### ​抗造能力（鲁棒性）​

+ 快速运动：哪怕机器人转得像陀螺（1000度/秒），也能稳住不飘。
+ ​杂乱环境：比如堆满杂物的仓库，LiDAR点云再乱也能找到规律。
+ 低成本设备：甚至能用便宜雷达，适合无人机、小车等。

## XV-Viewer

### XV-Viewer参数

+ x, y, z: 相机的位置信息
+ pithch, yaw, roll: 相机的姿态信息
+ Travelled distance: 总移动距离
+ To origin: 相机到原点的距离
+ Features: 特征点数量
+ Inliers: 被识别为有效的、可靠的特征点
+ Keyframes: 关键帧数
+ 3D points: 3D特征点数量

### VIO模式

+ 视觉惯性里程计（Visual-Inertial Odometry，VIO）是一种融合视觉和惯性传感器数据的技术，用于估计机器人的位置和姿态
+ 视觉传感器（如相机）用于获取环境的图像信息，惯性传感器（如陀螺仪和加速度计）用于测量机器人的运动状态
+ 汉明距离: 比较两个二进制字符串, 统计它们有多少个位置上的0/1值不同, 相当于玩“找不同”游戏，数两个字符串中有多少处差异
